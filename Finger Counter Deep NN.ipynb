{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.utils import shuffle\n",
    "import tkinter as tk\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processX(frame):\n",
    "    frame = frame.reshape(frame.shape[0],-1)\n",
    "    frame = frame.reshape(frame.shape[0] * frame.shape[1], 1)\n",
    "    frame = frame/255\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511\n",
      "(72, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "y = np.loadtxt(\"dataPoints/labels.txt\",delimiter = \",\")\n",
    "y = y.reshape(y.shape[0],1)\n",
    "path = r'dataPoints/All'\n",
    "counter = 0\n",
    "scale_percent = 10 # percent of original size\n",
    "width = int(1280 * scale_percent / 100)\n",
    "height = int(720 * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        img = cv2.imread(path+'/'+file, cv2.IMREAD_UNCHANGED)\n",
    "        resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        data.append(resized)\n",
    "print(len(data))\n",
    "#Lets look at an example picture\n",
    "cv2.imshow(\"Resized image\", data[0])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert List of images to one numpy\n",
    "X_orig = np.array(data)\n",
    "#Flatten the input\n",
    "X = X_orig.reshape(X_orig.shape[0],-1).T\n",
    "X.shape\n",
    "#Standardize\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "X = X.T\n",
    "randomize = np.arange(len(X))\n",
    "np.random.shuffle(randomize)\n",
    "X = X[randomize]\n",
    "y = y[randomize]\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27648, 511)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    return np.maximum(0,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reluPrime(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidPrime(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processY(Y,num):\n",
    "    return (Y == num).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initParams(dims):\n",
    "    params = {}\n",
    "    #initialize the Weights and biases\n",
    "    np.random.seed(1)\n",
    "    for l in range(1,len(dims)):\n",
    "        params[\"W\" + str(l)] = np.random.randn(dims[l],dims[l-1]) * 0.01\n",
    "        params[\"b\" + str(l)] = np.zeros((dims[l],1))\n",
    "    #Assert Param sizes\n",
    "    assert(params['W' + str(l)].shape == (dims[l], dims[l-1]))\n",
    "    assert(params['b' + str(l)].shape == (dims[l], 1))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardProp(params,X):\n",
    "    #One cycle of Forward Prop\n",
    "    L = int(len(params)/2)\n",
    "    cache = {}\n",
    "    A_prev = X\n",
    "    A = X\n",
    "    cache[\"A0\"] = X\n",
    "    for l in range(1,L):\n",
    "        # Get Vars from the dict\n",
    "        W = params[\"W\"+str(l)]\n",
    "        b = params[\"b\"+str(l)]\n",
    "        # Compute single forward prop step\n",
    "        Z = np.dot(W,A_prev) + b\n",
    "        A = relu(Z)\n",
    "        A_prev = A\n",
    "        #store in the cache dict\n",
    "        cache[\"Z\"+str(l)] = Z\n",
    "        cache[\"A\"+str(l)] = A\n",
    "        \n",
    "    #Last Sigmoid Step\n",
    "    #Get vars\n",
    "    W = params[\"W\"+str(L)]\n",
    "    b = params[\"b\"+str(L)]\n",
    "    #Compute\n",
    "    Z = np.dot(W,A_prev) + b\n",
    "    A = sigmoid(Z)\n",
    "    #store\n",
    "    cache[\"Z\"+str(L)] = Z\n",
    "    cache[\"A\"+str(L)] = A\n",
    "    return cache,A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(Yhat,Y):\n",
    "    #Compute the cost\n",
    "    Yhat = Yhat.T\n",
    "    m = Y.shape[0]\n",
    "    cost = (-1/m) * np.sum(np.multiply(np.log(Yhat),Y) + np.multiply(np.log(1-Yhat),(1-Y)))\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backProp(cache, params, Y, AL):\n",
    "    # initialization\n",
    "    grads = {}\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    m = (Y.shape[1])\n",
    "    L = int(len(cache)/2)\n",
    "    dA = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    ZL = cache[\"Z\"+str(L)]\n",
    "    dZ = sigmoidPrime(dA,ZL)\n",
    "    dW = (1/m) * np.dot(dZ,cache[\"A\"+str(L-1)].T)\n",
    "    db = (1/m) * np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(params[\"W\"+str(L)].T,dZ)\n",
    "    #store\n",
    "    grads[\"dW\"+str(L)] = dW\n",
    "    grads[\"db\"+str(L)] = db\n",
    "    grads[\"dA\"+str(L-1)] = dA_prev\n",
    "    \n",
    "    #For the relu function\n",
    "    for l in range(L-1,0,-1):\n",
    "        dA = grads[\"dA\"+str(l)]\n",
    "        Z = cache[\"Z\"+str(l)]\n",
    "        dZ = reluPrime(dA,Z)\n",
    "        dW = (1/m) * np.dot(dZ,cache[\"A\"+str(l-1)].T)\n",
    "        db = (1/m) * np.sum(dZ,axis=1,keepdims=True)\n",
    "        dA_prev = np.dot(params[\"W\"+str(l)].T,dZ)\n",
    "        #store em\n",
    "        grads[\"dW\"+str(l)] = dW\n",
    "        grads[\"db\"+str(l)] = db\n",
    "        grads[\"dA\"+str(l-1)] = dA_prev\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParams(params,grads,learning_rate):\n",
    "    #update params\n",
    "    L = int(len(params)/2)\n",
    "    for l in range(L):\n",
    "        params[\"W\"+str(l+1)] = params[\"W\"+str(l+1)] - learning_rate * grads[\"dW\"+str(l+1)]\n",
    "        params[\"b\"+str(l+1)] = params[\"b\"+str(l+1)] - learning_rate * grads[\"db\"+str(l+1)]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model(dims,X,Y,learning_rate,numIters):\n",
    "    #initialize Parameters\n",
    "    params = initParams(dims)\n",
    "    #now to loop\n",
    "    for i in range(numIters):\n",
    "        #forward propagation\n",
    "        cache,yHat = forwardProp(params,X)\n",
    "        #back propagation\n",
    "        grads = backProp(cache,params,Y,yHat)\n",
    "        #update parameters\n",
    "        params = updateParams(params,grads,learning_rate)\n",
    "        #print cost occasionally\n",
    "        if i%100 == 0:\n",
    "            costVal = cost(yHat,Y)\n",
    "            print(\"Cost after iteration {}: {}\".format(i, costVal))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,params):\n",
    "    confidence=[]\n",
    "    for i in range(5):\n",
    "        curr_params = params[i]\n",
    "        L = int(len(curr_params)/2)\n",
    "        A_prev = X\n",
    "        A = X\n",
    "        for l in range(1,L):\n",
    "            # Get Vars from the dict\n",
    "            W = curr_params[\"W\"+str(l)]\n",
    "            b = curr_params[\"b\"+str(l)]\n",
    "            # Compute single forward prop step\n",
    "            Z = np.dot(W,A_prev) + b\n",
    "            A = relu(Z)\n",
    "            A_prev = A\n",
    "        W = curr_params[\"W\"+str(L)]\n",
    "        b = curr_params[\"b\"+str(L)]\n",
    "        #Compute\n",
    "        Z = np.dot(W,A_prev) + b\n",
    "        A = sigmoid(Z)\n",
    "        confidence.append(A)\n",
    "    return confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeParams(paramsList):\n",
    "    for i in range(1,6):\n",
    "        data = paramsList[i-1]\n",
    "        np.save('parameters/params'+str(i)+'.npy',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6931618564875948\n",
      "Cost after iteration 100: 0.5474529189234908\n",
      "Cost after iteration 200: 0.5107684219192102\n",
      "Cost after iteration 300: 0.49989601901502284\n",
      "Cost after iteration 400: 0.49630390811960196\n",
      "Cost after iteration 500: 0.4950228655951196\n",
      "Cost after iteration 600: 0.4945232302405878\n",
      "Cost after iteration 700: 0.49428158956036405\n",
      "Cost after iteration 800: 0.49409242824324395\n",
      "Cost after iteration 900: 0.4938290506402814\n",
      "Cost after iteration 1000: 0.4932773539039249\n",
      "Cost after iteration 1100: 0.4916422061318059\n",
      "Cost after iteration 1200: 0.48246641305821225\n",
      "Cost after iteration 1300: 0.3725952813710431\n",
      "Cost after iteration 1400: 0.38011790983552934\n",
      "Cost after iteration 1500: 0.04132489029080448\n",
      "Cost after iteration 1600: 0.013441243282025986\n",
      "Cost after iteration 1700: 0.0055842735571361626\n",
      "Cost after iteration 1800: 0.003133989639652689\n",
      "Cost after iteration 1900: 0.0020462569470888997\n",
      "Cost after iteration 2000: 0.0014627373939903397\n",
      "Cost after iteration 2100: 0.0011110780733377484\n",
      "Cost after iteration 2200: 0.0008814686045232344\n",
      "Cost after iteration 2300: 0.0007219282751796193\n",
      "Cost after iteration 2400: 0.0006059126855077048\n",
      "Cost after iteration 0: 0.6931634023296477\n",
      "Cost after iteration 100: 0.5474371806045886\n",
      "Cost after iteration 200: 0.5107378506227269\n",
      "Cost after iteration 300: 0.4998479782922667\n",
      "Cost after iteration 400: 0.49623180120666444\n",
      "Cost after iteration 500: 0.4949106820492083\n",
      "Cost after iteration 600: 0.4943241202241497\n",
      "Cost after iteration 700: 0.49387912499835473\n",
      "Cost after iteration 800: 0.49310079207983576\n",
      "Cost after iteration 900: 0.49035181769833047\n",
      "Cost after iteration 1000: 0.465814872411533\n",
      "Cost after iteration 1100: 0.3764809307490329\n",
      "Cost after iteration 1200: 0.3081098068119189\n",
      "Cost after iteration 1300: 0.271107045861828\n",
      "Cost after iteration 1400: 0.14472216507302668\n",
      "Cost after iteration 1500: 0.2614603587704266\n",
      "Cost after iteration 1600: 0.08559559393719063\n",
      "Cost after iteration 1700: 0.03949112708113038\n",
      "Cost after iteration 1800: 0.042060178675711615\n",
      "Cost after iteration 1900: 0.01023018649384147\n",
      "Cost after iteration 2000: 0.004949022988494818\n",
      "Cost after iteration 2100: 0.0029272002888490003\n",
      "Cost after iteration 2200: 0.001962164399212115\n",
      "Cost after iteration 2300: 0.0014266884310337254\n",
      "Cost after iteration 2400: 0.0010969291024268207\n",
      "Cost after iteration 0: 0.6931666660720339\n",
      "Cost after iteration 100: 0.5530561135211257\n",
      "Cost after iteration 200: 0.5179379567790969\n",
      "Cost after iteration 300: 0.5076329736046521\n",
      "Cost after iteration 400: 0.5042773584101056\n",
      "Cost after iteration 500: 0.5031046676604863\n",
      "Cost after iteration 600: 0.502661429155081\n",
      "Cost after iteration 700: 0.5024634681299112\n",
      "Cost after iteration 800: 0.5023357493468893\n",
      "Cost after iteration 900: 0.5022005464478109\n",
      "Cost after iteration 1000: 0.5019993904189459\n",
      "Cost after iteration 1100: 0.501634741191273\n",
      "Cost after iteration 1200: 0.500850319025868\n",
      "Cost after iteration 1300: 0.49870984376060035\n",
      "Cost after iteration 1400: 0.49078340401877013\n",
      "Cost after iteration 1500: 0.4542831045832005\n",
      "Cost after iteration 1600: 0.3416940341072637\n",
      "Cost after iteration 1700: 0.26643028013120446\n",
      "Cost after iteration 1800: 0.48612308500833284\n",
      "Cost after iteration 1900: 0.22683997536340772\n",
      "Cost after iteration 2000: 0.07975656523898855\n",
      "Cost after iteration 2100: 0.013557098828726091\n",
      "Cost after iteration 2200: 0.005871657171726097\n",
      "Cost after iteration 2300: 0.003223294923280439\n",
      "Cost after iteration 2400: 0.002065368156627505\n",
      "Cost after iteration 0: 0.6931637466451941\n",
      "Cost after iteration 100: 0.5549008842259003\n",
      "Cost after iteration 200: 0.520289162752333\n",
      "Cost after iteration 300: 0.5101474899621276\n",
      "Cost after iteration 400: 0.5068185429268205\n",
      "Cost after iteration 500: 0.5055796899083188\n",
      "Cost after iteration 600: 0.5049428750069793\n",
      "Cost after iteration 700: 0.5041969260548168\n",
      "Cost after iteration 800: 0.5020154281583752\n",
      "Cost after iteration 900: 0.48623261839555076\n",
      "Cost after iteration 1000: 0.405812903655842\n",
      "Cost after iteration 1100: 0.24500501388488427\n",
      "Cost after iteration 1200: 0.16084775389112982\n",
      "Cost after iteration 1300: 0.02255714857528178\n",
      "Cost after iteration 1400: 0.008429571766291256\n",
      "Cost after iteration 1500: 0.003951252464683184\n",
      "Cost after iteration 1600: 0.002278640975147374\n",
      "Cost after iteration 1700: 0.0015182155301779032\n",
      "Cost after iteration 1800: 0.0011061221670810193\n",
      "Cost after iteration 1900: 0.0008546806898558166\n",
      "Cost after iteration 2000: 0.0006880662721646275\n",
      "Cost after iteration 2100: 0.0005708490851600807\n",
      "Cost after iteration 2200: 0.0004847566060907419\n",
      "Cost after iteration 2300: 0.0004192127623734732\n",
      "Cost after iteration 2400: 0.0003678474576863569\n",
      "Cost after iteration 0: 0.6931530220588988\n",
      "Cost after iteration 100: 0.5549150132482399\n",
      "Cost after iteration 200: 0.5203252946134178\n",
      "Cost after iteration 300: 0.5102149706223404\n",
      "Cost after iteration 400: 0.506940916316904\n",
      "Cost after iteration 500: 0.5058084263830913\n",
      "Cost after iteration 600: 0.5053866701219595\n",
      "Cost after iteration 700: 0.5052112512924912\n",
      "Cost after iteration 800: 0.5051132283223428\n",
      "Cost after iteration 900: 0.5050259179781819\n",
      "Cost after iteration 1000: 0.5049145706964245\n",
      "Cost after iteration 1100: 0.5047397830857588\n",
      "Cost after iteration 1200: 0.5044210819831899\n",
      "Cost after iteration 1300: 0.5037434701323283\n",
      "Cost after iteration 1400: 0.5019210574728439\n",
      "Cost after iteration 1500: 0.4945756362956006\n",
      "Cost after iteration 1600: 0.42749810209284067\n",
      "Cost after iteration 1700: 0.2806126526016663\n",
      "Cost after iteration 1800: 0.13003534474367132\n",
      "Cost after iteration 1900: 0.30149579071714133\n",
      "Cost after iteration 2000: 0.32882534447438994\n",
      "Cost after iteration 2100: 0.006241109994255709\n",
      "Cost after iteration 2200: 0.0029112182099853834\n",
      "Cost after iteration 2300: 0.0017769868655516249\n",
      "Cost after iteration 2400: 0.0012347508325432739\n"
     ]
    }
   ],
   "source": [
    "all_Y = {}\n",
    "all_Y[\"Y1\"] = processY(y,1)\n",
    "all_Y[\"Y2\"] = processY(y,2)\n",
    "all_Y[\"Y3\"] = processY(y,3)\n",
    "all_Y[\"Y4\"] = processY(y,4)\n",
    "all_Y[\"Y5\"] = processY(y,5)\n",
    "allParams = []\n",
    "for i in range(1,6):\n",
    "    allParams.append(NN_model([27648,150,70,20,1],X,all_Y[\"Y\"+str(i)],0.03,2500))\n",
    "storeParams(allParams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
